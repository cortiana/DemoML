{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure plots will be added to the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# some imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to generate a pseudo time series\n",
    "# add some random noise to it\n",
    "rng = np.random.RandomState(2016)\n",
    "def f(t):\n",
    "    #return np.sin(t)+0.001*t*t+5*rng.uniform(size=len(t))-0.00001*t*t*t\n",
    "    return 1+np.sin(t)+0.001*t*t+5*rng.uniform(size=len(t))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let generate the time axis, 100 ptx from 0 to 100.\n",
    "# then plot the function f(t).\n",
    "\n",
    "datasetsize =100\n",
    "\n",
    "X = np.linspace(0, datasetsize, datasetsize)\n",
    "Y = f(X)\n",
    "plt.plot(X, f(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now insert some test code for SVM from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(iris.data.shape)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(iris.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(iris.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_index = 3\n",
    "y_index = 0\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "permutation = rng.permutation(len(X))\n",
    "X, y = X[permutation], y[permutation]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.5, random_state=1999)\n",
    "print(\"Labels for training and testing data\")\n",
    "print(train_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "print(\"Fraction Correct\")\n",
    "print(np.sum(pred_y == test_y) / float(len(test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "correct_idx = np.where(pred_y == test_y)[0]\n",
    "print(correct_idx)\n",
    "incorrect_idx = np.where(pred_y != test_y)[0]\n",
    "print(incorrect_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot two dimensions\n",
    "colors = [\"darkblue\", \"darkgreen\", \"gray\"]\n",
    "for n, color in enumerate(colors):\n",
    "    idx = np.where(test_y == n)[0]\n",
    "    plt.scatter(test_X[idx, 0], test_X[idx, 1], color=color, label=\"Class %s\" % str(n))\n",
    "plt.scatter(test_X[incorrect_idx, 0], test_X[incorrect_idx, 1], color=\"darkred\")\n",
    "# Make xlim larger to accommodate legend\n",
    "plt.xlim(3, 9)\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Iris Classification results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let us see if the SVN optimization works, see http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# Utility function to move the midpoint of a colormap to be around\n",
    "# the values of interest.\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "##############################################################################\n",
    "# Load and prepare data set\n",
    "#\n",
    "# dataset for grid search\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dataset for decision function visualization: we only keep the first two\n",
    "# features in X and sub-sample the dataset to keep only 2 classes and\n",
    "# make it a binary classification problem.\n",
    "\n",
    "X_2d = X[:, :2]\n",
    "X_2d = X_2d[y > 0]\n",
    "y_2d = y[y > 0]\n",
    "y_2d -= 1\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "##############################################################################\n",
    "# Train classifiers\n",
    "#\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(y, n_iter=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Now we need to fit a classifier for all parameters in the 2d version\n",
    "# (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_2d, y_2d)\n",
    "        classifiers.append((C, gamma, clf))\n",
    "\n",
    "##############################################################################\n",
    "# visualization\n",
    "#\n",
    "# draw visualization of parameter effects\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # visualize decision function for these parameters\n",
    "    plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "              size='medium')\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu_r)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "# plot the scores of the grid\n",
    "# grid_scores_ contains parameter settings and scores\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in grid.grid_scores_]\n",
    "scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "#\n",
    "# The score are encoded as colors with the hot colormap which varies from dark\n",
    "# red to bright yellow. As the most interesting scores are all located in the\n",
    "# 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "# as to make it easier to visualize the small variations of score values in the\n",
    "# interesting range while not brutally collapsing all the low score values to\n",
    "# the same color.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
